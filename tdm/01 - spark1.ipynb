{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Una introducción a Spark con Python\n",
                "\n",
                "#### Rafael Caballero, modificado por Pablo C. Cañizares\n",
                "\n",
                "Casi todo el código extraído del libro *Big Data con Python*\n",
                "\n",
                "## 0: Preparación\n",
                "\n",
                "\n",
                "#### Windows\n",
                "\n",
                "El mismo código debería funcionar en otros sistemas \n",
                "\n",
                "* \n",
                "* Instrucciones para linux: https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f\n",
                "* Instrucciones para windows: https://medium.com/@ashish1512/how-to-setup-apache-spark-pyspark-on-jupyter-ipython-notebook-3330543ab307\n",
                "* Instrucciones para mac: https://sparkbyexamples.com/pyspark/how-to-install-pyspark-on-mac/\n",
                "\n",
                "En el laboratorio tenemos el problema de que no podemos hacer nuestras propias instalaciones; por ello podemos copiar la carpeta spark hlocal\\tdm y ejecutar el siguiente código"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# copiar la carpeta spark en c:\\hlocal\\tdm\n",
                "import os\n",
                "\n",
                "# cambiamos las variables del sistema\n",
                "spark = \"/opt/homebrew/bin/spark\"\n",
                "# en el path se añade\n",
                "path = os.environ.get(\"PATH\")\n",
                "path = path + \";\" + spark + \"\\\\bin;\"\n",
                "os.environ[\"PATH\"] = path\n",
                "os.environ[\"SPARK_HOME\"] = spark\n",
                "os.environ[\"HADOOP_HOME\"] = spark\n",
                "\n",
                "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
                "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"notebook\"\n",
                "\n",
                "# si da problema con collect quizás haya que poner java_home\n",
                "os.environ[\"JAVA_HOME\"] = \"/usr/bin/java\"\n",
                "os.environ[\"PATH\"] = os.environ.get(\"JAVA_HOME\") + \"//bin;\" + path\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/02 17:30:30 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.9.20.158 instead (on interface wlp0s20f3)\n",
                        "24/10/02 17:30:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
                        "24/10/02 17:30:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-----+\n",
                        "| hola|\n",
                        "+-----+\n",
                        "|spark|\n",
                        "+-----+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "import findspark\n",
                "\n",
                "findspark.init()\n",
                "\n",
                "import pyspark  # only run after findspark.init()\n",
                "from pyspark.sql import SparkSession\n",
                "\n",
                "spark = SparkSession.builder.getOrCreate()\n",
                "\n",
                "df = spark.sql(\"\"\"select 'spark' as hola \"\"\")\n",
                "df.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1: Acciones"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Al importar pyspark ya tenemos una variable spark con la conexión con Spark creada. Para manejar RDDs nos interesará extraer de ella el llamado *sparkContext*:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "sc = spark.sparkContext\n",
                "r = sc.parallelize([1, 2, 3])  # Crea un RDD con los valores 1,2,3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Veamos el tipo de la variable r"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "pyspark.rdd.RDD"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "type(r)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[4, 9, 16]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "24/10/02 17:30:44 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
                    ]
                }
            ],
            "source": [
                "cuadrados = sc.parallelize([i * i for i in range(100)])\n",
                "l = cuadrados.take(5)\n",
                "l[2:]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Acciones  collect, take y count"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Las *acciones* son las que lanzan un cómputo.\n",
                "** collect ** recupera todo un RDD como si se tratara de un array\n",
                "\n",
                "*Ojo*: Si hacemos esto nos traemos toda la colección al ordenador en el que estamos, ¡eso no es big data!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[0,\n",
                            " 1,\n",
                            " 4,\n",
                            " 9,\n",
                            " 16,\n",
                            " 25,\n",
                            " 36,\n",
                            " 49,\n",
                            " 64,\n",
                            " 81,\n",
                            " 100,\n",
                            " 121,\n",
                            " 144,\n",
                            " 169,\n",
                            " 196,\n",
                            " 225,\n",
                            " 256,\n",
                            " 289,\n",
                            " 324,\n",
                            " 361,\n",
                            " 400,\n",
                            " 441,\n",
                            " 484,\n",
                            " 529,\n",
                            " 576,\n",
                            " 625,\n",
                            " 676,\n",
                            " 729,\n",
                            " 784,\n",
                            " 841,\n",
                            " 900,\n",
                            " 961,\n",
                            " 1024,\n",
                            " 1089,\n",
                            " 1156,\n",
                            " 1225,\n",
                            " 1296,\n",
                            " 1369,\n",
                            " 1444,\n",
                            " 1521,\n",
                            " 1600,\n",
                            " 1681,\n",
                            " 1764,\n",
                            " 1849,\n",
                            " 1936,\n",
                            " 2025,\n",
                            " 2116,\n",
                            " 2209,\n",
                            " 2304,\n",
                            " 2401,\n",
                            " 2500,\n",
                            " 2601,\n",
                            " 2704,\n",
                            " 2809,\n",
                            " 2916,\n",
                            " 3025,\n",
                            " 3136,\n",
                            " 3249,\n",
                            " 3364,\n",
                            " 3481,\n",
                            " 3600,\n",
                            " 3721,\n",
                            " 3844,\n",
                            " 3969,\n",
                            " 4096,\n",
                            " 4225,\n",
                            " 4356,\n",
                            " 4489,\n",
                            " 4624,\n",
                            " 4761,\n",
                            " 4900,\n",
                            " 5041,\n",
                            " 5184,\n",
                            " 5329,\n",
                            " 5476,\n",
                            " 5625,\n",
                            " 5776,\n",
                            " 5929,\n",
                            " 6084,\n",
                            " 6241,\n",
                            " 6400,\n",
                            " 6561,\n",
                            " 6724,\n",
                            " 6889,\n",
                            " 7056,\n",
                            " 7225,\n",
                            " 7396,\n",
                            " 7569,\n",
                            " 7744,\n",
                            " 7921,\n",
                            " 8100,\n",
                            " 8281,\n",
                            " 8464,\n",
                            " 8649,\n",
                            " 8836,\n",
                            " 9025,\n",
                            " 9216,\n",
                            " 9409,\n",
                            " 9604,\n",
                            " 9801]"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "r = sc.parallelize([i * i for i in range(100)])\n",
                "r.collect()  # Falla en algunas versiones de Java!!!!!!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Es mucho más normal recuperar solo unos cuantos elementos. De esto se encarga *take(n)* que devuelve los n primeros miembros del rdd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
                    ]
                }
            ],
            "source": [
                "print(r.take(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Por último, *count* nos dice de cuántos elementos consta un RDD"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "texto = sc.textFile(\"quijote.txt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1347\n",
                        "['El ingenioso hidalgo don Quijote de la Mancha', '', '', 'TASA', '', 'Yo, Juan Gallo de Andrada, escribano de Cámara del Rey nuestro señor, de', 'los que residen en su Consejo, certifico y doy fe que, habiendo visto por', 'los señores dél un libro intitulado El ingenioso hidalgo de la Mancha,', 'compuesto por Miguel de Cervantes Saavedra, tasaron cada pliego del dicho', 'libro a tres maravedís y medio; el cual tiene ochenta y tres pliegos, que']\n"
                    ]
                }
            ],
            "source": [
                "print(texto.count())\n",
                "print(texto.take(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Reduce, fold"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*reduce* es una de las operaciones claves en Spark. \n",
                "Reduce todos los elementos de un RDD a uno solo. \n",
                "Para ello toma una función que aplica:\n",
                "    * Primero a los dos primeros elementos, dando un resultado r1\n",
                "    * Luego a r1 y al tercer elemento, dando r2\n",
                "    * ... así hasta rn-1 y el último elemento, que dan el valor final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1 2\n",
                        "3 3\n",
                        "6 4\n",
                        "10 5\n",
                        "15\n"
                    ]
                }
            ],
            "source": [
                "def add(x, y):\n",
                "    print(x, y)\n",
                "    return x + y\n",
                "\n",
                "\n",
                "r = sc.parallelize(range(1, 6))\n",
                "print(r.reduce(add))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "15\n"
                    ]
                }
            ],
            "source": [
                "# Otra forma de lograr lo mismo: funciones lambda\n",
                "print(r.reduce(lambda x, y: x + y))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "fold() es similar a reduce, excepto porque toma un 'valor cero' inicial, al que podemos llamar z. \n",
                "Dado un valor z y una lista l, la función se aplica\n",
                "    * Primero a z y al primer elemento de l, dando un resultado r1\n",
                "    * Luego a r1 y al segundo elemento de l, dando r2\n",
                "    * ... así hasta rn-1 y el último elemento, que dan el valor final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "15\n"
                    ]
                }
            ],
            "source": [
                "print(r.fold(0, lambda x, y: x + y))  # raro!!!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2: Transformaciones"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Map\n",
                "\n",
                "Aplica una función a todos los miembros de un RDD. La salida es otro RDD con tantos elementos como tenía la entrada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1347\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[45, 0, 0, 4, 0]"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def longitud(s):\n",
                "    return len(s)\n",
                "\n",
                "\n",
                "longitudes = texto.map(longitud)\n",
                "print(longitudes.count())\n",
                "longitudes.take(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('EL', 2),\n",
                            " ('INGENIOSO', 9),\n",
                            " ('HIDALGO', 7),\n",
                            " ('DON', 3),\n",
                            " ('QUIJOTE', 7),\n",
                            " ('DE', 2),\n",
                            " ('LA', 2),\n",
                            " ('MANCHA', 6),\n",
                            " ('', 0),\n",
                            " ('', 0),\n",
                            " ('TASA', 4),\n",
                            " ('', 0),\n",
                            " ('YO,', 3),\n",
                            " ('JUAN', 4),\n",
                            " ('GALLO', 5),\n",
                            " ('DE', 2),\n",
                            " ('ANDRADA,', 8),\n",
                            " ('ESCRIBANO', 9),\n",
                            " ('DE', 2),\n",
                            " ('CÁMARA', 6)]"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def divide(s):\n",
                "    return s.split(\" \")\n",
                "\n",
                "\n",
                "##################################\n",
                "texto.flatMap(divide).map(lambda s: s.upper()).map(lambda s: (s, len(s))).take(20)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Filter\n",
                "\n",
                "Aplica una función booleana a todos los miembros de un RDD. La salida es otro RDD que solo tiene los miembros para los que la función devuelve True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[0,\n",
                            " 2,\n",
                            " 4,\n",
                            " 6,\n",
                            " 8,\n",
                            " 10,\n",
                            " 12,\n",
                            " 14,\n",
                            " 16,\n",
                            " 18,\n",
                            " 20,\n",
                            " 22,\n",
                            " 24,\n",
                            " 26,\n",
                            " 28,\n",
                            " 30,\n",
                            " 32,\n",
                            " 34,\n",
                            " 36,\n",
                            " 38,\n",
                            " 40,\n",
                            " 42,\n",
                            " 44,\n",
                            " 46,\n",
                            " 48]"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "numeros = sc.parallelize(range(50))\n",
                "numeros.filter(lambda n: (n % 2) == 0).collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ejemplo complejo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "('', 840)\n"
                    ]
                }
            ],
            "source": [
                "def maxpareja(s1, s2):\n",
                "    if s1[1] > s2[1]:\n",
                "        r = s1\n",
                "    else:\n",
                "        r = s2\n",
                "    return r\n",
                "\n",
                "\n",
                "pareja = (\n",
                "    texto.flatMap(lambda line: line.split(\" \"))\n",
                "    .map(lambda s: s.upper())\n",
                "    .map(lambda word: (word, 1))\n",
                "    .reduceByKey(lambda a, b: a + b)\n",
                "    .reduce(maxpareja)\n",
                ")\n",
                "\n",
                "print(pareja)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('John', 34), ('José', 40)]"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "personas = list(((\"John\", 34), (\"Ana\", 19), (\"José\", 40)))\n",
                "# Creación de un RDD a partir de la lista\n",
                "personasRDD = sc.parallelize(personas)\n",
                "\n",
                "# Transformación: Filtrar personas mayores de 30 años\n",
                "treintaRDD = personasRDD.filter(lambda persona: persona[1] > 30)\n",
                "\n",
                "# Acción: Recolectar el resultado y mostrarlo\n",
                "treintaRDD.collect()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ejercicio"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "leer el quijote en un RDD y cuente el número de frases que contienen el texto 'merced'.\n",
                "Nota: no importa que la palabra venga dentro de otra palabra, se contará igual\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "15"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "texto.filter(lambda line: \"merced\" in line).count()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "tdm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
